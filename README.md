After analyzing the decisions I made when completing the “MoralMachine” test, I noticed a couple of factors that I prioritized when making a choice. Among those factors were the following: saving people who followed the law, minimizing the amount of people who would be hurt, prioritizing women and children for safety, putting human lives above animal ones, and not intervening if intervention will ultimately lead to the same net impact. 

All of the factors stated above were looked at in accordance to my moral compas. When it came to situations where there is no real correct answer, the only thing I had left was to try and arrive at the closest thing to a not wrong decision. I ended up creating my own little rubric to go off of. Probably the most important thing was to save as many people as possible, and if there was no obvious answer with that outcome, I decided to save those that followed the law as I think that it would be an even worse unfair outcome if someone that followed the rules died and the ones that did not survived. If saving more lives meant that a lot of animals had to die that was an easier decision for me as I value human lives more than animals. Should all of those decisions not lead to an obvious answer, I would make sure to prioritize women and children, as I think that it is society’s duty to protect the women and children.

When the test showed its results based on my decisions, it got some things on the nose, some where a little innacurate, and the otherse were flat out incorrect. When it came to “Saving more lives”, “Upholding the Law”, “Gender Preference”, and “Species Preference”, it was pretty accurate in my heavy favouratism. There were other factors that I did focus on such as Avoiding Intervention, but not nearly as much as the results state I did. Finally, there were certain factors that were completely innacurate in their weight on my decisision, such as the “Social Value Preference” where the results stated that I fully favoured those with higher social status, and completely disregarded those with lower status. Overall, I would say that although the test gets some stuff right, it is overall unreliable as it shows that machines can focus on certain details that are completely unrelated to the actual narrative of what happened, and therefore come up with a completely different scenario, and is therefore dangerous to use in scenarios where those decisions can have real effects on people or any entitites for that matter.
